{
  "questions": [
    {
      "id": 52,
      "question": "A mobile application requires occasional, unpredictable access to machine learning predictions. The app’s usage fluctuates significantly throughout the day, leading to periods of high traffic and very low usage at off-peak times. Which deployment strategy in Amazon SageMaker would optimize costs while still ensuring scalability during peak periods?\n\nBatch Transform\n\nExplicación\nBatch Transform is for batch processing, not for dynamically fluctuating real-time requests.\n\nReal-Time Inference Endpoint\n\nExplicación\nReal-Time Inference Endpoints require continuous infrastructure, which is not cost-effective for applications with sporadic usage patterns.",
      "options": [
        "Batch Transform",
        "Real-Time Inference Endpoint",
        "Serverless Inference Endpoint",
        "Asynchronous Inference Endpoint"
      ],
      "correct_answers": [
        "Serverless Inference Endpoint"
      ],
      "references": [],
      "topic": "Deployment and Orchestration of ML Workflows",
      "Source": "https://rgitsc.udemy.com/course/aws-machine-learning-engineer-associate-practice-exams/learn/quiz/6615561/result/1592040951",
      "Practice test": "AWS Machine Learning Engineer - Associate Practice Test 4"
    }
  ]
}