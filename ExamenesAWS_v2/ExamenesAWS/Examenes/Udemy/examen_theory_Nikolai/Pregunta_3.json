{
  "questions": [
    {
      "id": 3,
      "question": "A data science team wants to automate their machine learning workflow using SageMaker Pipelines. After the model is trained and registered, they need to automatically trigger batch inference jobs on new data stored in an Amazon S3 bucket. Which combination of services should they use to achieve this?",
      "options": [
        "Use AWS Lambda to directly transform the data in S3 and register the model in SageMaker Pipelines.",
        "Use Amazon Redshift to process the data and SageMaker Pipelines to deploy the model as an endpoint for inference.",
        "Configure an Amazon CloudWatch Event to trigger a SageMaker batch transform job when new data is uploaded to S3.",
        "Use Amazon Athena to query the new data and SageMaker Studio to run batch transform jobs."
      ],
      "correct_answers": [
        "Configure an Amazon CloudWatch Event to trigger a SageMaker batch transform job when new data is uploaded to S3."
      ],
      "references": [],
      "topic": "Deployment and Orchestration of ML Workflows",
      "Source": "https://rgitsc.udemy.com/course/aws-certified-machine-learning-engineer-associate-mla-c01-exam-prep/learn/quiz/6550303/results?expanded=1497470169",
      "Practice test": "AWS Certified Machine Learning Engineer - Associate MLA-C01"
    }
  ]
}