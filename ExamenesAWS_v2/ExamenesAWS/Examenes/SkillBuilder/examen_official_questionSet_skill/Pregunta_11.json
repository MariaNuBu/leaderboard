{
  "questions": [
    {
      "id": 11,
      "question": "Case Study - 3 Questions\n\nA company wants to implement an internal employee chatbot that can answer questions that are related to internal company topics and processes. The chatbot will use a generative AI approach and large language models (LLMs) to interact with users. The relevant information is currently held in an unstructured format in thousands of PDF documents in the company's document management system. An ML engineer must implement the chatbot solution.\n\nWhich solution will make the companyâ€™s PDF documents searchable in an LLM chatbot for question-answering by using retrieval augmented generation (RAG)? (Select TWO.)",
      "options": [
        "A\nEmbed the documents into an Amazon OpenSearch Service vector database for RAG.",
        "B\nIngest the documents into an Amazon S3 bucket for RAG.",
        "C\nIngest the documents into an Amazon Elastic File System (Amazon EFS) volume for RAG.",
        "D\nIngest the documents into an Amazon Redshift database for RAG.",
        "E\nEmbed the documents into Amazon Bedrock knowledge bases for RAG."
      ],
      "correct_answers": [
        "A\nEmbed the documents into an Amazon OpenSearch Service vector database for RAG.",
        "E\nEmbed the documents into Amazon Bedrock knowledge bases for RAG."
      ],
      "references": [],
      "topic": "",
      "Source": "",
      "Practice test": "Official Practice Question Set: AWS Certified Machine Learning Engineer - Associate (MLA-C01 - English)"
    }
  ]
}