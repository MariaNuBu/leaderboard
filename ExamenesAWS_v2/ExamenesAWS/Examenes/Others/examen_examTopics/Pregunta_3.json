{
  "questions": [
    {
      "id": 3,
      "question": "Case Study -\nA company is building a web-based AI application by using Amazon SageMaker. The application will provide the following capabilities and features: ML experimentation, training, a central model registry, model deployment, and model monitoring.\nThe application must ensure secure and isolated use of training data during the ML lifecycle. The training data is stored in Amazon S3.\nThe company must implement a manual approval-based workflow to ensure that only approved models can be deployed to production endpoints.\nWhich solution will meet this requirement?",
      "options": [
        "A. Use SageMaker Experiments to facilitate the approval process during model registration.",
        "B. Use SageMaker ML Lineage Tracking on the central model registry. Create tracking entities for the approval process.",
        "C. Use SageMaker Model Monitor to evaluate the performance of the model and to manage the approval.",
        "D. Use SageMaker Pipelines. When a model version is registered, use the AWS SDK to change the approval status to \"Approved.\" Most Voted"
      ],
      "correct_answers": [
        "D. Use SageMaker Pipelines. When a model version is registered, use the AWS SDK to change the approval status to \"Approved.\" Most Voted"
      ],
      "references": [
        "https://www.examtopics.com/exams/amazon/aws-certified-machine-learning-engineer-associate-mla-c01"
      ],
      "topic": "",
      "Source": "https://www.examtopics.com/exams/amazon/aws-certified-machine-learning-engineer-associate-mla-c01",
      "Practice test": "ExamTopics"
    }
  ]
}