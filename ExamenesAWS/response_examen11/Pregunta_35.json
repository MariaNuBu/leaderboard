{
  "questions": [
    {
      "id": 35,
      "question": "PREGUNTA 35\n\nTOPIC: 2.3 Analyze model performance\n\nA data scientist is training a deep learning neural network by using Amazon SageMaker. The data scientist wants to debug the model to identify and address model convergence issues. The data scientist wants to use real-time monitoring to determine if there is a sampling imbalance between classes.\n\nWhich solution will meet these requirements with the LEAST operational overhead?",
      "options": [
        "A\nSet up a SageMaker training job that is configured for TensorBoard. Access TensorBoard through the SageMaker console. Examine the training output visualizations in TensorBoard for sampling imbalance.",
        "B\nSet up a SageMaker training job that is configured to include SageMaker Debugger. Start the training job and monitor for sampling imbalance by using SageMaker Debugger built-in rules.",
        "C\nSet up a SageMaker training job with remote debugging enabled. Access the training container through AWS Systems Manager to monitor the training jobs for sampling imbalance.",
        "D\nSet up a SageMaker training job that is configured to include SageMaker Debugger. Create a SageMaker Debugger custom rule to monitor sampling imbalance. Use the SageMaker Debugger APIs to invoke the custom rule."
      ],
      "correct_answers": [
        "B\nSet up a SageMaker training job that is configured to include SageMaker Debugger. Start the training job and monitor for sampling imbalance by using SageMaker Debugger built-in rules."
      ],
      "references": [],
      "topic": "2.3 Analyze model performance",
      "Source": "",
      "Practice test": "Official Pretest: AWS Certified Machine Learning Engineer - Associate"
    }
  ]
}